余:
项目总目标：实现一个汽车（前期）安全的模型（）能够快速自适应在不同类型的车上，并（后期）满足不同车型的硬件限制（算力与存储）。

前期：安全模型部分
后期：模型压缩，对汽车安全模型进行压缩


11. 5 会议记录  本期目标依旧：
在小样本的情况下，快速更新原车模型（csc）到另一辆车（CDC）上。
项目走向：方法1：A车的模型，meta-learning去学习B车模型。
验证：真实B车数据去验证B车模型
如何训练B车模型？
1. 确定模型基于图片还是时间序列的
1.1图片：如何把现有的数据转成图片.CNN- Meta-learning
1.2时间序列：Lstm,图片输出形式.Lstm -Meta-learning
方法2：A车的生成模型，训练成B车的生成模型(Conditional Generative Adversarial Nets)，Meta-learning+生成器，生成B车的数据，训练成B的模型。
验证：生成器生成的B车数据，训练成分类模型，真实B车数据去验证
如何训练B车的生成模型？


陈焕师兄和导师们讨论运行代码Meta-learning-lstm———只有少部分的训练集去训练我们原有车模型，通过学习的方法去学习原有车的模型在少部分训练集上的收敛
过程，以优化收敛过程，达到少部分训练集快速收敛的结果。调参之后，精度仍然不高，尝试换种类型的meta—learning。

会议指出，师兄继续meta-learning的其他方法实验进行调参，优化方法，达到高精度。

师兄代李雄，周磊强及朱琦汇报上周工作。
李雄，周磊强用lstm做安全检测，有着延迟较高的缺点。
朱琦用AR自动回归模型做安全检测，效果不错。

会议指出：lstm的使用细节或许存在漏洞，可以使用少点预测多点，比如100个点预测10个点，窗口预测，用lstm做分类等，AR的模型进行预测，效果不错，可以继续做下去。

余震汇报关于模型压缩，目标是对一个比较大的网络完成剪枝，上周的做法是不用工具的话，形成了一个自己工具代码（表示如果这种方法高效就继续积累工具代码），现在
找到的代码并不是能够拿到模型就能剪枝的而且输出延迟和压缩量的（非常希望能有这样的代码）。目前的话能通过用自用代码替换pytorch下网络层和卷积层，实现非结构剪枝（不改变网络结构，仅仅通过置零来无效化网络参数）。

会议指出，报告需要看到结果，不是做了什么，要展示出计算速度和压缩量，慢慢积累代码。

余:
刚申请git hub账号的同学请把账号发上来，我邀请进组，进组之后把自己的每周报告整合在一个文档里，从上到下记录自己做了什么，体会及问题，以后更新维护自己的
这份文档。
关于github的使用-上面发的帖子看完加上官网的入门指导，就能做自己的文档维护了。用readme可以生成图片格式的文档 这个自己摸索
