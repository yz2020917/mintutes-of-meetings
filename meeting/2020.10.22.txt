10.22  会议记录  本期目标依旧：
在小样本的情况下，快速更新原车模型（csc）到另一辆车（CDC）上。
项目走向：方法1：A车的模型，meta-learning去学习B车模型。
验证：真实B车数据去验证B车模型
如何训练B车模型？
1. 确定模型基于图片还是时间序列的
1.1图片：如何把现有的数据转成图片.CNN- Meta-learning
1.2时间序列：Lstm,图片输出形式.Lstm -Meta-learning
方法2：A车的生成模型，训练成B车的生成模型(Conditional Generative Adversarial Nets)，Meta-learning+生成器，生成B车的数据，训练成B的模型。
验证：生成器生成的B车数据，训练成分类模型，真实B车数据去验证
如何训练B车的生成模型？


陈焕师兄和导师们讨论了实现上述任务中的遇到的代码问题，及写论文方面的经验，尝试运行代码Meta-learning-lstm———只有少部分的训练集去训练我们原有车模型，
通过学习的方法去学习原有车的模型在少部分训练集上的收敛过程，以优化收敛过程，达到少部分训练集快速收敛的结果。也报告了两位师弟的学习情况。
会议指出，两位师弟应当准确把握做项目的目标是什么，自己做的东西是什么，自己做的东西要达到什么样的效果，基于此，去探索解决问题的方法，可以咨询师兄有关完成任务的方法，
实践需要自己动手做。师兄继续meta-learning的实验，及完成论文。


余震汇报上周工作，PPT 讲述 Deep Compression 及网上代码的实验，讲的不好。
会议指出：应当理解并掌握网上代码，获得能使用Deep Compression方法的能力，指定任务：抛开网上开源的代码中的默认模型，找一个比较大的网络使用它的方法进行剪枝，
做出详细的实验报告。
